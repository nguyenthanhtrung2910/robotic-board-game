trainer:
  env_args:
    colors_map: assets/csv_files/colors_map.csv
    targets_map: assets/csv_files/targets_map.csv
    required_mail: 4
    robot_colors: 
      - r
      - b
    num_robots_per_player: 1
    with_battery: false
    random_num_steps: false
    max_step: 500
  num_train_envs: 16
  num_test_envs: 16
  batch_size: 64
  update_freq: 200
  test_freq: 100
  episodes_per_train: 2000
  episodes_per_test: 64

agent:
  count: 2
  agent_class: src.agents.dqn_agent.DQNAgent
  model_class: tianshou.utils.net.common.Net
  model_args:
    state_shape: 6
    action_shape: 5
    hidden_sizes: [256, 256, 128, 128, 64, 64]
    norm_layer: torch.nn.LayerNorm
    device: cpu
    dueling_param:
      - {}
      - {}
  policy_class: tianshou.policy.DQNPolicy
  policy_args:
    discount_factor: 0.99
    estimation_step: 30
    target_update_freq: 500
    is_double: true
  memory_class: tianshou.data.PrioritizedVectorReplayBuffer
  memory_args:
    total_size: 2_500_000
    buffer_num: 32
    alpha: 0.6
    beta: 0.4
  update_per_step: 0.05
  learning_rate: 0.0001
  trained_ckpt: null

# max_eps should be also small if using NoisyLinear
max_eps: 1.0
min_eps: 0.05
eps_rate: 0.9987
begin_beta: 0.4
end_beta: 1.0
beta_rate: 0.004
episode_to_save: 500
reward_to_stop: 19
best_ckpt: checkpoints/best.pth
last_ckpt: checkpoints/last.pth


